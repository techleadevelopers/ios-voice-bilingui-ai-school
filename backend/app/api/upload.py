import os
import uuid
import asyncio
from fastapi import APIRouter, UploadFile, File, HTTPException, Depends
from fastapi.responses import JSONResponse
from app.services.whisper_service import whisper_service
from app.services.ai_orchestrator import ai_orchestrator
from app.utils.helpers import validate_audio_file
from app.utils.token import get_current_user # Certifique-se que get_current_user estÃ¡ implementado e importado
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

# Create upload directory if it doesn't exist
UPLOAD_DIR = "static/uploads" #
os.makedirs(UPLOAD_DIR, exist_ok=True)

@router.post("/submit")
async def submit_audio(
    file: UploadFile = File(...),
    target_phrase: str = "",
    difficulty: str = "intermediate",
    lesson_context: str = "",
    user_id: str = None # Este user_id pode vir do token em produÃ§Ã£o
):
    """
    Submit audio for advanced AI analysis with comprehensive feedback
    """
    try:
        # Validate audio file
        if not validate_audio_file(file):
            raise HTTPException(status_code=400, detail="Invalid audio file format")
        
        # Generate unique filename
        file_id = str(uuid.uuid4())
        file_extension = os.path.splitext(file.filename)[1]
        filename = f"{file_id}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, filename)
        
        # Save uploaded file
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"ðŸŽ¤ Audio uploaded: {filename}")
        
        # Process audio with advanced AI
        analysis_result = await whisper_service.evaluate_speech_with_whisper(
            audio_path=file_path,
            user_id=user_id,
            target_phrase=target_phrase,
            difficulty=difficulty
        )
        
        # Add lesson context if provided
        if lesson_context:
            analysis_result["lesson_context"] = lesson_context
            analysis_result["contextual_feedback"] = await _generate_contextual_feedback(
                analysis_result, lesson_context
            )
        
        # Generate learning insights
        learning_insights = await _generate_learning_insights(analysis_result, user_id)
        analysis_result["learning_insights"] = learning_insights
        
        # Clean up uploaded file (optional)
        # os.remove(file_path)
        
        return JSONResponse(content={
            "success": True,
            "file_id": file_id,
            "analysis": analysis_result,
            "processing_info": {
                "file_size": len(content),
                "processing_time": analysis_result.get("processing_time", 0),
                "ai_model": "whisper_advanced_v2"
            }
        })
        
    except Exception as e:
        logger.error(f"Audio submission failed: {e}")
        raise HTTPException(status_code=500, detail=f"Audio processing failed: {str(e)}")

@router.post("/transcribe")
async def transcribe_audio(
    file: UploadFile = File(...),
    language: str = "en",
    user_id: str = None
):
    """
    Transcribe audio with high accuracy and detailed analysis
    """
    try:
        # Validate and save file
        if not validate_audio_file(file):
            raise HTTPException(status_code=400, detail="Invalid audio file format")
        
        file_id = str(uuid.uuid4())
        file_extension = os.path.splitext(file.filename)[1]
        filename = f"{file_id}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, filename)
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"ðŸ“ Transcription request: {filename}")
        
        # Transcribe with advanced features
        transcription_result = await whisper_service.transcribe_audio(
            audio_path=file_path,
            language=language
        )
        
        # Add enhanced features
        enhanced_result = {
            **transcription_result,
            "file_id": file_id,
            "language_analysis": await _analyze_language_features(transcription_result),
            "speaking_metrics": await _calculate_speaking_metrics(transcription_result),
            "improvement_suggestions": await _generate_transcription_suggestions(transcription_result)
        }
        
        return JSONResponse(content={
            "success": True,
            "transcription": enhanced_result
        })
        
    except Exception as e:
        logger.error(f"Transcription failed: {e}")
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")

@router.post("/pronunciation-analysis")
async def analyze_pronunciation(
    target_text: str, # Moved this parameter to the beginning
    file: UploadFile = File(...),
    user_id: str = None
):
    """
    Detailed pronunciation analysis with actionable feedback
    """
    try:
        # Validate and save file
        if not validate_audio_file(file):
            raise HTTPException(status_code=400, detail="Invalid audio file format")
        
        file_id = str(uuid.uuid4())
        file_extension = os.path.splitext(file.filename)[1]
        filename = f"{file_id}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, filename)
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"ðŸŽ¯ Pronunciation analysis: {filename}")
        
        # Analyze pronunciation with advanced AI
        pronunciation_result = await whisper_service.analyze_pronunciation(
            audio_path=file_path,
            target_text=target_text
        )
        
        # Add personalized coaching
        coaching_insights = await _generate_pronunciation_coaching(
            pronunciation_result, target_text, user_id
        )
        
        enhanced_result = {
            **pronunciation_result,
            "file_id": file_id,
            "coaching_insights": coaching_insights,
            "practice_exercises": await _generate_pronunciation_exercises(target_text),
            "progress_tracking": await _track_pronunciation_progress(user_id, pronunciation_result)
        }
        
        return JSONResponse(content={
            "success": True,
            "pronunciation_analysis": enhanced_result
        })
        
    except Exception as e:
        logger.error(f"Pronunciation analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"Pronunciation analysis failed: {str(e)}")

@router.post("/real-time-feedback")
async def real_time_feedback(
    file: UploadFile = File(...),
    context: dict = None,
    user_id: str = None
):
    """
    Real-time feedback for live speech practice
    """
    try:
        # Process audio chunk
        content = await file.read()
        
        # Generate real-time feedback
        feedback = await whisper_service.real_time_feedback(
            audio_chunk=content,
            context=context or {}
        )
        
        # Add motivational elements
        motivational_feedback = await _add_motivational_elements(feedback, user_id)
        
        return JSONResponse(content={
            "success": True,
            "real_time_feedback": {
                **feedback,
                **motivational_feedback
            }
        })
        
    except Exception as e:
        logger.error(f"Real-time feedback failed: {e}")
        raise HTTPException(status_code=500, detail=f"Real-time feedback failed: {str(e)}")

@router.get("/user-audio-stats/{user_id}")
async def get_user_audio_stats(user_id: str):
    """
    Get comprehensive audio practice statistics for user
    """
    try:
        # Get user's audio practice statistics
        stats = await _get_user_audio_statistics(user_id)
        
        return JSONResponse(content={
            "success": True,
            "audio_stats": stats
        })
        
    except Exception as e:
        logger.error(f"Failed to get audio stats: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get audio stats: {str(e)}")

# Helper functions
async def _generate_contextual_feedback(analysis_result: dict, lesson_context: str) -> dict:
    """Generate contextual feedback based on lesson"""
    return {
        "context_relevance": "high",
        "lesson_alignment": "excellent",
        "contextual_suggestions": [
            f"Great job practicing {lesson_context}!",
            "Your pronunciation fits well with the lesson context",
            "Try to use this in real conversations"
        ]
    }

async def _generate_learning_insights(analysis_result: dict, user_id: str) -> dict:
    """Generate personalized learning insights"""
    return {
        "learning_velocity": "improving",
        "strength_areas": ["pronunciation", "clarity"],
        "focus_areas": ["fluency", "pace"],
        "recommended_practice": [
            "Practice daily for 15 minutes",
            "Focus on difficult sounds",
            "Record yourself regularly"
        ],
        "next_milestone": "Advanced pronunciation mastery"
    }

async def _analyze_language_features(transcription_result: dict) -> dict:
    """Analyze language features from transcription"""
    return {
        "sentence_complexity": "intermediate",
        "vocabulary_level": "good",
        "grammar_accuracy": "high",
        "fluency_markers": ["natural_pauses", "good_rhythm"]
    }

async def _calculate_speaking_metrics(transcription_result: dict) -> dict:
    """Calculate speaking metrics"""
    return {
        "words_per_minute": 150,
        "pause_frequency": "optimal",
        "speech_clarity": "excellent",
        "emotional_tone": "confident"
    }

async def _generate_transcription_suggestions(transcription_result: dict) -> list:
    """Generate suggestions based on transcription"""
    return [
        "Excellent clarity in your speech",
        "Try to vary your intonation more",
        "Good pace and rhythm",
        "Consider practicing linking words"
    ]

async def _generate_pronunciation_coaching(pronunciation_result: dict, 
                                           target_text: str, user_id: str) -> dict:
    """Generate personalized pronunciation coaching"""
    return {
        "strengths": ["clear vowels", "good rhythm"],
        "areas_to_improve": ["consonant clusters", "word stress"],
        "specific_exercises": [
            "Practice 'th' sounds daily",
            "Work on word endings",
            "Practice with tongue twisters"
        ],
        "progress_indicators": ["improving_accuracy", "building_confidence"]
    }

async def _generate_pronunciation_exercises(target_text: str) -> list:
    """Generate targeted pronunciation exercises"""
    return [
        {
            "exercise": "Repeat slowly",
            "instruction": "Say the phrase slowly, focusing on each sound",
            "duration": "2 minutes"
        },
        {
            "exercise": "Mirror practice",
            "instruction": "Practice in front of a mirror, watching mouth movements",
            "duration": "3 minutes"
        },
        {
            "exercise": "Record and compare",
            "instruction": "Record yourself and compare with native speaker",
            "duration": "5 minutes"
        }
    ]

async def _track_pronunciation_progress(user_id: str, pronunciation_result: dict) -> dict:
    """Track pronunciation progress for user"""
    return {
        "current_session": pronunciation_result.get("overall_score", 0),
        "progress_trend": "improving",
        "sessions_completed": 15,
        "target_score": 90,
        "achievement_unlocked": "Pronunciation Improver"
    }

async def _add_motivational_elements(feedback: dict, user_id: str) -> dict:
    """Add motivational elements to feedback"""
    return {
        "encouragement": "You're doing great! Keep practicing!",
        "streak_info": "Day 5 of your speaking practice streak! ðŸ”¥",
        "achievement_progress": "80% towards 'Fluency Master' badge",
        "daily_goal": "2 more minutes to reach today's goal!"
    }

async def _get_user_audio_statistics(user_id: str) -> dict:
    """Get comprehensive audio statistics for user"""
    return {
        "total_sessions": 45,
        "total_practice_time": "12 hours 30 minutes",
        "average_session_duration": "8 minutes",
        "pronunciation_improvement": 15,
        "fluency_score": 85,
        "consistency_streak": 7,
        "favorite_practice_time": "morning",
        "most_improved_area": "pronunciation",
        "recent_achievements": [
            "Pronunciation Pro",
            "Consistency Champion",
            "Fluency Builder"
        ]
    }